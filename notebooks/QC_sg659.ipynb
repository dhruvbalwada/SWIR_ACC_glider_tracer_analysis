{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81f4ba05",
   "metadata": {},
   "source": [
    "## Additional QC for sg659\n",
    "\n",
    "The glider data has been processed by the base station on 2021/09/24. The software on the base stations already included some QC procedures documented [here](https://gliderfs2.coas.oregonstate.edu/sgliderweb/Seaglider_Quality_Control_Manual.html).\n",
    "\n",
    "Here we do some:\n",
    "- additional QC on the data, using the methods documented at https://glidertools.readthedocs.io/en/latest/quality_control.html\n",
    "-  Calibration adjustments to remove bias, and match the observations between the two gliders. \n",
    "- Sorting and binning the data to bring it to a cleaner and easier to analyze form.\n",
    "\n",
    "*Note that the out from this notebook is stored in this repo, and used for all the analysis for this paper. So most users might not need to run this notebook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e15ead05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import glidertools as gt\n",
    "from cmocean import cm as cmo\n",
    "\n",
    "import gsw\n",
    "import extra_funcs as ef \n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbea1ca5",
   "metadata": {},
   "source": [
    "#### Open the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606bc136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this to be the path where the nc files downloaded from the location \n",
    "# in the read me are stored. \n",
    "data_dir = '/Users/dhruvbalwada/OneDrive/sogos_data'\n",
    "nc_files_659 = data_dir + '/data/raw/gliders/SOGOS_Apr19/sg659/*.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d6487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = [\n",
    "    'ctd_depth',\n",
    "    'ctd_pressure',\n",
    "    'salinity',\n",
    "    'temperature'\n",
    "]\n",
    "# There are more variables measured by the gliders, but in this study we only \n",
    "# use these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8401d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DIMENSION: ctd_data_point\n",
      "{ctd_pressure, temperature, ctd_depth, ctd_time, latitude, salinity, longitude}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 492/492 [00:02<00:00, 168.73it/s]\n"
     ]
    }
   ],
   "source": [
    "ds_dict = gt.load.seaglider_basestation_netCDFs(\n",
    "    nc_files_659, var_names,\n",
    "    return_merged=False,\n",
    "    keep_global_attrs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891b5a54",
   "metadata": {},
   "source": [
    "#### Remove non-needed dives, do additive correction, add attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5362a237",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_659 = ds_dict['ctd_data_point']\n",
    "# throw out data points after we stopped sampling the region for science\n",
    "# and the gliders were being turned on just so they could get back to be picked by a ship. \n",
    "ctd_659 = ctd_659.where(ctd_659.longitude<40, drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "920f8eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an additive correction is made to the temperature, \n",
    "# to match to the Argo float measurements launched with the glider.\n",
    "# This bias was estimated by Lily Dove at Caltech.\n",
    "temp_dic = ctd_659['temperature'].attrs.copy()\n",
    "ctd_659['temperature'] = ctd_659['temperature']+0.045\n",
    "ctd_659['temperature'].attrs = temp_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eae063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load O2 data \n",
    "# (we need to use this because lily did some O2 calibration that I don't know how to do. )\n",
    "# So just directly load in the processed data. \n",
    "O2_659 = xr.load_dataset('../data/O2_659.nc')\n",
    "O2_659['oxygen'].attrs['standard_name'] = 'Oxygen'\n",
    "O2_659['oxygen'].attrs['units'] = 'mumol/kg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e626337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time axis to day format \n",
    "ctd_659['days'] = ef.datetime2ytd(ctd_659.ctd_time_dt64)\n",
    "O2_659['days'] = ef.datetime2ytd(O2_659.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d7c333",
   "metadata": {},
   "source": [
    "#### Do some useful thermodynamic transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a45dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the absolute salinity, conservative temperature, and potential density\n",
    "\n",
    "SA = gsw.SA_from_SP(ctd_659.salinity, ctd_659.ctd_pressure, \n",
    "                   ctd_659.longitude, ctd_659.latitude)\n",
    "CT = gsw.CT_from_t(SA, ctd_659.temperature, ctd_659.ctd_pressure)\n",
    "\n",
    "ctd_659['SA'] = SA\n",
    "ctd_659['CT'] = CT\n",
    "ctd_659['sigma0'] = gsw.sigma0(SA, CT)\n",
    "\n",
    "ctd_659['SA'].attrs['standard_name'] = 'Absolute Salinity'\n",
    "ctd_659['SA'].attrs['units'] = 'g/kg'\n",
    "\n",
    "ctd_659['CT'].attrs['standard_name'] = 'Conservative Temperature'\n",
    "ctd_659['CT'].attrs['units'] = 'deg C'\n",
    "ctd_659['CT'].attrs['comment'] = ctd_659['temperature'].attrs['comment']\n",
    "\n",
    "ctd_659['sigma0'].attrs['standard_name'] = 'Potential Density Anomaly'\n",
    "ctd_659['sigma0'].attrs['units'] = 'kg/m^3'\n",
    "ctd_659['sigma0'].attrs['comment'] = 'Calculated using GSW'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99128d65",
   "metadata": {},
   "source": [
    "#### Median based filter and remove some bad dives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2d77bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_window = 15 # this choice made based on work above\n",
    "# Do some despiking using a median filter\n",
    "salt_iqr = gt.cleaning.outlier_bounds_iqr(ctd_659.SA, multiplier=1.5)\n",
    "salt_base, salt_spike = gt.cleaning.despike(salt_iqr, window_size=filter_window, spike_method='median') # this is to get rid of some odd profiles\n",
    "\n",
    "#temp_iqr = gt.cleaning.outlier_bounds_iqr(ctd_660.temperature, multiplier=2.5) # this is not a good idea for temp as it gets rid of a lot of the cold anomalies, which are real. \n",
    "temp_base, temp_spike = gt.cleaning.despike(ctd_659.CT, window_size=filter_window, spike_method='median')\n",
    "\n",
    "O2_iqr = gt.cleaning.outlier_bounds_iqr(O2_659.oxygen, multiplier=1.5)\n",
    "O2_base, O2_spike = gt.cleaning.despike(O2_iqr, window_size=filter_window, spike_method='median') # this is to get rid of some odd profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46b47314",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_659['SA_QC'] = salt_base\n",
    "ctd_659['CT_QC'] = temp_base\n",
    "\n",
    "# We need to move O2 to ctd values\n",
    "O2_659['oxygen_QC'] = O2_base\n",
    "ctd_659['oxygen'] = xr.DataArray(np.interp(ctd_659.days, O2_659.days, O2_659.oxygen_QC),\n",
    "                                dims= ctd_659.dims,\n",
    "                                coords= ctd_659.coords).rename('oxygen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc8e0063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this to get rid of some of the bad dives. \n",
    "# We will however have to manually remove a few dives that are not picked by this. \n",
    "ctd_659['oxygen_QC']  = gt.cleaning.horizontal_diff_outliers(ctd_659.dives, ctd_659.ctd_pressure, ctd_659.oxygen, \n",
    "                                          multiplier=1.5, depth_threshold=400, mask_frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4427ffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_659['sigma0_QC'] = gsw.sigma0(ctd_659.SA_QC, ctd_659.CT_QC)\n",
    "ctd_659['sigma0_QC'].attrs['standard_name'] = 'Potential Density Anomaly'\n",
    "ctd_659['sigma0_QC'].attrs['units'] = 'kg/m^3'\n",
    "ctd_659['sigma0_QC'].attrs['comment'] = 'Calculated using GSW'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6303e03",
   "metadata": {},
   "source": [
    "### Sort the data \n",
    "Let's sort the variables based on density. \"Manually finish the overturn\".\n",
    "We will sort the density and move the corresponding T and S with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "648e2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = ctd_659.groupby('dives')\n",
    "\n",
    "ds_dives = {}\n",
    "ds_dives_nonan = {}\n",
    "ds_dives_sorted = {}\n",
    "\n",
    "dim ='ctd_data_point'\n",
    "\n",
    "for k, i in grp.groups.items():\n",
    "    # extract each dive and sort in depth\n",
    "    ds_dives[k] = ctd_659.isel(**{dim: i}).sortby('ctd_depth') \n",
    "    # remove nans\n",
    "    ds_dives_nonan[k] = ds_dives[k].where(~np.isnan(ds_dives[k].SA_QC) & ~np.isnan(ds_dives[k].CT_QC), drop=True)\n",
    "    # sort by density\n",
    "    # note that this has also sorted some variables that we are not looking to be sorted.\n",
    "    ds_dives_sorted[k] = ds_dives_nonan[k].sortby('sigma0_QC')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a270e13b",
   "metadata": {},
   "source": [
    "### Binning the data\n",
    "\n",
    "Since every single glider profile is on a slightly different grid we grid all the data to a uniform grid in depth/pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91ca34c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin the regular data\n",
    "pres_bins = np.arange(0,1001,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22f209b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin the sorted data \n",
    "# For this we need to do these loops since we had split the data into individual dives. \n",
    "k=2.\n",
    "dens_sorted_gridded = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_sorted[k].sigma0_QC, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0)\n",
    "temp_sorted_gridded = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_sorted[k].CT_QC, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0)\n",
    "salt_sorted_gridded = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_sorted[k].SA_QC, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0)\n",
    "O2_sorted_gridded = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_sorted[k].oxygen_QC, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0)\n",
    "\n",
    "time_sorted_gridded = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_nonan[k].ctd_time, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0)\n",
    "lat_sorted_gridded = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_nonan[k].latitude, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0)\n",
    "lon_sorted_gridded = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_nonan[k].longitude, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "435332d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop to do it over all dives \n",
    "\n",
    "for k in ds_dives_sorted.keys():\n",
    "    if len(ds_dives_nonan[k].ctd_data_point)>0:\n",
    "        temp = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_sorted[k].sigma0_QC, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0);\n",
    "    \n",
    "        dens_sorted_gridded = xr.concat([dens_sorted_gridded, temp], dim='dives')\n",
    "        \n",
    "        temp = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_sorted[k].CT_QC, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0);\n",
    "    \n",
    "        temp_sorted_gridded = xr.concat([temp_sorted_gridded, temp], dim='dives')\n",
    "        \n",
    "        temp = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_sorted[k].SA_QC, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0);\n",
    "    \n",
    "        salt_sorted_gridded = xr.concat([salt_sorted_gridded, temp], dim='dives')\n",
    "        \n",
    "        temp = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_sorted[k].oxygen_QC, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0);\n",
    "    \n",
    "        O2_sorted_gridded = xr.concat([O2_sorted_gridded, temp], dim='dives')\n",
    "        \n",
    "        temp = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_nonan[k].ctd_time, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0);\n",
    "    \n",
    "        time_sorted_gridded = xr.concat([time_sorted_gridded, temp], dim='dives')\n",
    "        \n",
    "        temp = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_nonan[k].latitude, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0);\n",
    "    \n",
    "        lat_sorted_gridded = xr.concat([lat_sorted_gridded, temp], dim='dives')\n",
    "        \n",
    "        temp = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_nonan[k].longitude, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0);\n",
    "    \n",
    "        lon_sorted_gridded = xr.concat([lon_sorted_gridded, temp], dim='dives')\n",
    "        \n",
    "# Throw away the first column since it has been added twice. \n",
    "dens_sorted_gridded = dens_sorted_gridded[:,1:]\n",
    "temp_sorted_gridded = temp_sorted_gridded[:,1:]\n",
    "salt_sorted_gridded = salt_sorted_gridded[:,1:]\n",
    "O2_sorted_gridded   = O2_sorted_gridded[:,1:]\n",
    "time_sorted_gridded = time_sorted_gridded[:,1:]\n",
    "lat_sorted_gridded  = lat_sorted_gridded[:,1:]\n",
    "lon_sorted_gridded  = lon_sorted_gridded[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f72583",
   "metadata": {},
   "source": [
    "#### Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ceb165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_659_grid = xr.merge([dens_sorted_gridded.rename('sigma0'), \n",
    "                        salt_sorted_gridded.rename('SA'), \n",
    "                        temp_sorted_gridded.rename('CT'),\n",
    "                        O2_sorted_gridded.rename('Oxygen'),\n",
    "                        time_sorted_gridded.rename('time'), \n",
    "                        lat_sorted_gridded.rename('latitude'), \n",
    "                        lon_sorted_gridded.rename('longitude')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46d4f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_659_grid.to_netcdf('../data/sg_659_4m_binned.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50412420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0352b8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906d1ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120f6c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "512417b9",
   "metadata": {},
   "source": [
    "# The code below is what was used to check and reach the decisions that are made in the steps taken above. You might only want to run this if you want to explore how the choices were made. It is not needed to generate the data, and some cells are a repetition of the concise version above. \n",
    "\n",
    "**This was all done using the data processed by Geoff Shilling.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1881952",
   "metadata": {},
   "source": [
    "## Prepare glider data for scientific analysis\n",
    "\n",
    "The glider data has undergone a few things before coming to this stage. \n",
    "\n",
    "\n",
    "a) For 660 a thermal lag correction has already taken place on the basestation.   \n",
    "b) 659 data, which had recovery problems, has been converted to scientific units.  \n",
    "c) A correction was done to the T and S of the gliders to match them with surrounding water ($0.045$ is added to T of sg659, and $-0.18$ to the S of sg660.).  \n",
    "d) A 2-sigma correction was applied to the T-S profiles. \n",
    "\n",
    "\n",
    "Further details in https://www.overleaf.com/8417818782tmwbmnqrfjry\n",
    "\n",
    "\n",
    "Seaglider QC manual: https://gliderfs2.coas.oregonstate.edu/sgliderweb/Seaglider_Quality_Control_Manual.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fbbe9a",
   "metadata": {},
   "source": [
    "**One of the main goals is to make sure that the density field does not have any overturns. So smooth just enough for that and no more.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace5f00",
   "metadata": {},
   "source": [
    "### Some questions to think about when doing QC: \n",
    "- How do we know some data is bad? \n",
    "- One of the main concerns in the RTQCed data are overturns. How does one deal with them? Sort them?\n",
    "- What degree of further smoothing should be done to the RTQCed data? Median filters, bin averages etc? \n",
    "- Is there some objective way to determine that we are in a QC sweet spot? \n",
    "- What is the role for visual inspection? \n",
    "\n",
    "- What to do about the 659, which did not undergo RTQC and adjustments? \n",
    "- Do we try to apply the exact same procedures as would have been done by base station? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405472df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import glidertools as gt\n",
    "from cmocean import cm as cmo\n",
    "\n",
    "import gsw\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6ca433",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/dhruvbalwada/OneDrive/sogos_data'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091a4d2d",
   "metadata": {},
   "source": [
    "### ... \n",
    "We want to do: \n",
    "https://glidertools.readthedocs.io/en/latest/quality_control.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159e7f0b",
   "metadata": {},
   "source": [
    "## For 659\n",
    "\n",
    "This glider underwent all the RTQC. Here we check if any more QC is needed. \n",
    "\n",
    "*Note*: The dive numbers are calculated differently in Lily's files, where glider dive number was assigned by loop iteration number. This does not impact anything later, since the time and other things are correct and per data point. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a447c5",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949bdc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nc files directly\n",
    "# To see the files\n",
    "nc_files_659 = data_dir + '/data/raw/gliders/SOGOS_Apr19/sg659/*.nc'\n",
    "#gt.load.seaglider_show_variables(nc_files_659)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3192984",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    'ctd_depth',\n",
    "    'ctd_pressure',\n",
    "    'salinity',\n",
    "#    'salinity_qc',\n",
    "    'temperature',\n",
    "#    'temperature_qc'\n",
    "]\n",
    "# Don't need to get the qc flags since almost all the data point are fine for 660. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e739c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict = gt.load.seaglider_basestation_netCDFs(\n",
    "    nc_files_659, names,\n",
    "    return_merged=False,\n",
    "    keep_global_attrs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0025c2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_659 = ds_dict['ctd_data_point']\n",
    "ctd_659 = ctd_659.where(ctd_659.longitude<40, drop=True) # throw out data points after we stopped sampling and were just trying to get back to be picked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d36ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d49adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_659"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01768c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load O2 data (we need to use this because lily did some O2 calibration that I don't know how to do. )\n",
    "O2_659 = xr.load_dataset(data_dir + '/data/interim/gliders/sg659_20201010/O2_659.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e33fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime2ytd(time):\n",
    "    \"\"\"\" Return time in YTD format from datetime format.\"\"\"\n",
    "    return  (time - np.datetime64('2019-01-01'))/np.timedelta64(1, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f9c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_659['days'] = datetime2ytd(ctd_659.ctd_time_dt64)\n",
    "O2_659['days'] = datetime2ytd(O2_659.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc864d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA = gsw.SA_from_SP(ctd_659.salinity, ctd_659.ctd_pressure, \n",
    "                   ctd_659.longitude, ctd_659.latitude)\n",
    "CT = gsw.CT_from_t(SA, ctd_659.temperature, ctd_659.ctd_pressure)\n",
    "\n",
    "\n",
    "ctd_659['SA'] = SA\n",
    "ctd_659['CT'] = CT\n",
    "ctd_659['sigma0'] = gsw.sigma0(SA, CT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66440715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ab2c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad810d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.plot(ctd_659.dives, ctd_659.ctd_pressure, ctd_659.salinity, cmap = cmo.haline, robust=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b513d59",
   "metadata": {},
   "source": [
    "#### Figure out despiking choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3343b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths =np.array([3,5,7,10, 12, 15, 17, 20, 25, 30] )\n",
    "std_salt_spikes = 0.*lengths\n",
    "std_temp_spikes = 0.*lengths\n",
    "std_O2_spikes   = 0.*lengths\n",
    "\n",
    "despiked_salt = {}\n",
    "despiked_temp = {}\n",
    "despiked_O2   = {}\n",
    "\n",
    "for i, lens  in enumerate(lengths):\n",
    "    salt_base, salt_spike = gt.cleaning.despike(ctd_659.SA, window_size=lens, spike_method='median')    \n",
    "    temp_base, temp_spike = gt.cleaning.despike(ctd_659.CT, window_size=lens, spike_method='median')    \n",
    "    O2_base, O2_spike = gt.cleaning.despike(O2_659.oxygen, window_size=lens, spike_method='median')\n",
    "    \n",
    "    std_salt_spikes[i] = salt_spike.std().values\n",
    "    std_temp_spikes[i] = temp_spike.std().values    \n",
    "    std_O2_spikes[i] = O2_spike.std().values\n",
    "    \n",
    "    despiked_salt[lens] = {'base':salt_base, 'spikes':salt_spike}\n",
    "    despiked_temp[lens] = {'base':temp_base, 'spikes':temp_spike}\n",
    "    despiked_O2[lens] = {'base':O2_base, 'spikes':O2_spike}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b88897",
   "metadata": {},
   "source": [
    "Window size of 10-15 seems to be the sweet spot after which the spike size does not change much. \n",
    "The increase in spike size for temperature at higher values is likely a result of the filter starting to tap into the real signal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7fb59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lengths, std_salt_spikes, marker='o', label='SA')\n",
    "plt.plot(lengths, std_temp_spikes, marker='*', label='CT')\n",
    "plt.plot(lengths, std_O2_spikes, marker='o', label='Oxy')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.ylabel('Spike STD')\n",
    "plt.xlabel('Median window size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8dca31",
   "metadata": {},
   "source": [
    "### Look at the despiking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a155056",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "import panel as pn\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae3c076",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def profile_filtered(var = 'SA', dive_num=300): \n",
    "    \n",
    "    plot = ctd_660[var].where(ctd_660.dives==dive_num, drop=True).hvplot.line(x=var, y='ctd_depth')\n",
    "    \n",
    "    \n",
    "    temp = ctd_660\n",
    "    for i in [5, 12]:\n",
    "        temp[var+'_QC'] = despiked_salt[i]['base']\n",
    "    \n",
    "        plot = plot*temp.where(ctd_660.dives==dive_num, drop=True).hvplot.line(x=var+'_QC', y='ctd_depth')\n",
    "    \n",
    "    plot.opts(width=300, height=500, invert_yaxis=True, show_legend=True)\n",
    "    return plot\n",
    "discrete_slider2 = pn.widgets.DiscreteSlider(name='Dive number',\n",
    "                                           options= list(np.arange(1,510,0.5)),\n",
    "                                           value=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad1aa3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "layout_salt_QC = pn.interact(profile_filtered, dive_num= discrete_slider2)\n",
    "layout_salt_QC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea8a3a",
   "metadata": {},
   "source": [
    "It is a bit arbitrary, but seems like a median filter around 12 does a good job. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3984603f",
   "metadata": {},
   "source": [
    "### Despiking using median filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fea2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_window = 15 # this choice made based on work above\n",
    "# Do some despiking using a median filter\n",
    "salt_iqr = gt.cleaning.outlier_bounds_iqr(ctd_659.SA, multiplier=1.5)\n",
    "salt_base, salt_spike = gt.cleaning.despike(salt_iqr, window_size=filter_window, spike_method='median') # this is to get rid of some odd profiles\n",
    "\n",
    "#temp_iqr = gt.cleaning.outlier_bounds_iqr(ctd_660.temperature, multiplier=2.5) # this is not a good idea for temp as it gets rid of a lot of the cold anomalies, which are real. \n",
    "temp_base, temp_spike = gt.cleaning.despike(ctd_659.CT, window_size=filter_window, spike_method='median')\n",
    "\n",
    "O2_iqr = gt.cleaning.outlier_bounds_iqr(O2_659.oxygen, multiplier=1.5)\n",
    "O2_base, O2_spike = gt.cleaning.despike(O2_iqr, window_size=filter_window, spike_method='median') # this is to get rid of some odd profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7289e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_659['SA_QC'] = salt_base\n",
    "ctd_659['CT_QC'] = temp_base\n",
    "\n",
    "# We need to move O2 to ctd values\n",
    "O2_659['oxygen_QC'] = O2_base\n",
    "ctd_659['oxygen'] = xr.DataArray(np.interp(ctd_659.days, O2_659.days, O2_659.oxygen_QC),\n",
    "                                dims= ctd_659.dims,\n",
    "                                coords= ctd_659.coords).rename('oxygen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96c9831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this to get rid of some of the bad dives. \n",
    "# We will however have to manually remove a few dives that are not picked by this. \n",
    "ctd_659['oxygen_QC']  = gt.cleaning.horizontal_diff_outliers(ctd_659.dives, ctd_659.ctd_pressure, ctd_659.oxygen, \n",
    "                                          multiplier=1.5, depth_threshold=400, mask_frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d146055",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.plot(ctd_659.dives, ctd_659.ctd_pressure, ctd_659['oxygen_QC'], cmap = cmo.haline, robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fea5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SA = gsw.SA_from_SP(ctd_660.SA_QC, ctd_660.ctd_pressure, \n",
    "#                   ctd_660.longitude, ctd_660.latitude)\n",
    "#CT = gsw.CT_from_t(SA, ctd_660.CT_QC, ctd_660.ctd_pressure)\n",
    "ctd_659['sigma0_QC'] = gsw.sigma0(ctd_659.SA_QC, ctd_659.CT_QC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74b05a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_659['sigma0_QC'].attrs['standard_name'] = 'Potential Density Anomaly'\n",
    "ctd_659['sigma0_QC'].attrs['units'] = 'kg/m^3'\n",
    "ctd_659['sigma0_QC'].attrs['comment'] = 'Calculated using GSW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bdda31",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# hvplot setup to explore individual profiles\n",
    "\n",
    "def profile(var='SA', dive_num=300):\n",
    "    \n",
    "    dive_num = float(dive_num) \n",
    "    \n",
    "    plot = (ctd_660.where(ctd_660.dives==dive_num, drop=True).hvplot.line(x=var, y= 'ctd_depth')  *\n",
    "            ctd_660.where(ctd_660.dives==dive_num, drop=True).hvplot.line(x = var+ '_QC', y = 'ctd_depth',\n",
    "                                                                        line_width=1.) )\n",
    "    plot.opts(width=300, height=500, invert_yaxis=True )\n",
    "    if var=='CT':\n",
    "        plot.opts(xlim=(1.2, 3.5))\n",
    "    elif var=='SA': \n",
    "        plot.opts(xlim=(33.9, 35))\n",
    "    return plot\n",
    "\n",
    "discrete_slider = pn.widgets.DiscreteSlider(name='Dive number',\n",
    "                                           options= list(np.arange(1,510,0.5)),\n",
    "                                           value=300)\n",
    "\n",
    "layout_salt = pn.interact(profile, dive_num= discrete_slider)\n",
    "layout_temp = pn.interact(profile, var='CT', dive_num= discrete_slider)\n",
    "layout_dens = pn.interact(profile, var='sigma0', dive_num= discrete_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001336f6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pn.Column( pn.Row(layout_salt[1], layout_temp[1], layout_dens[1]), pn.Column('Profile explorer', layout_salt[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1898d7da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e1775bb",
   "metadata": {},
   "source": [
    "The above is great. However we choose to do a little more smoothing by binning to get a vertically gridded data set on a uniform grid. This will likely also help clean some of the overturns.  \n",
    "\n",
    "Realized that simply binning is not sufficient to get rid of all the overturns. We will use the approach of sorting the dataset based on density as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e632537",
   "metadata": {},
   "source": [
    "### Sort the data \n",
    "Let's sort the variables based on density. \"Manually finish the overturn\".\n",
    "We will sort the density and move the corresponding T and S with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a964bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = ctd_659.groupby('dives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c837b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dives = {}\n",
    "ds_dives_nonan = {}\n",
    "ds_dives_sorted = {}\n",
    "\n",
    "dim ='ctd_data_point'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ad1b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, i in grp.groups.items():\n",
    "    # extract each dive and sort in depth\n",
    "    ds_dives[k] = ctd_659.isel(**{dim: i}).sortby('ctd_depth') \n",
    "    # remove nans\n",
    "    ds_dives_nonan[k] = ds_dives[k].where(~np.isnan(ds_dives[k].SA_QC) & ~np.isnan(ds_dives[k].CT_QC), drop=True)\n",
    "    # sort by density\n",
    "    # note that this has also sorted some variables that we are not looking to be sorted.\n",
    "    ds_dives_sorted[k] = ds_dives_nonan[k].sortby('sigma0_QC')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f0405",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dives.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a17b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-1,0,1]\n",
    "ds_dives_nonan[120].sigma0.diff(dim).plot.hist(bins = bins)\n",
    "ds_dives_nonan[120].sigma0_QC.diff(dim).plot.hist(bins = bins, alpha=0.5);\n",
    "ds_dives_sorted[120].sigma0_QC.diff(dim).plot.hist(bins = bins, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df9994c",
   "metadata": {},
   "source": [
    "### Binning the data\n",
    "\n",
    "Since every single glider profile is on a slightly different grid we grid all the data to a uniform grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fd7a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin the regular data\n",
    "pres_bins = np.arange(0,1001,4)\n",
    "dens_gridded = gt.grid_data(ctd_659.dives, ctd_659.ctd_pressure, ctd_659.sigma0_QC, \n",
    "                           bins = pres_bins, interp_lim=0)\n",
    "temp_gridded = gt.grid_data(ctd_659.dives, ctd_659.ctd_pressure, ctd_659.CT_QC, \n",
    "                           bins = pres_bins, interp_lim=0)\n",
    "salt_gridded = gt.grid_data(ctd_659.dives, ctd_659.ctd_pressure, ctd_659.SA_QC, \n",
    "                           bins = pres_bins, interp_lim=0)\n",
    "O2_gridded = gt.grid_data(ctd_659.dives, ctd_659.ctd_pressure, ctd_659.oxygen_QC, \n",
    "                           bins = pres_bins, interp_lim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72e441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin the sorted data \n",
    "# For this we need to do these loops since we had split the data into individual dives. \n",
    "k=2.\n",
    "dens_sorted_gridded = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_sorted[k].sigma0_QC, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0)\n",
    "temp_sorted_gridded = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_sorted[k].CT_QC, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0)\n",
    "salt_sorted_gridded = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_sorted[k].SA_QC, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0)\n",
    "O2_sorted_gridded = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_sorted[k].oxygen_QC, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0)\n",
    "\n",
    "time_sorted_gridded = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_nonan[k].ctd_time, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0)\n",
    "lat_sorted_gridded = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_nonan[k].latitude, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0)\n",
    "lon_sorted_gridded = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_nonan[k].longitude, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8aa625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop to do it over all dives \n",
    "\n",
    "for k in ds_dives_sorted.keys():\n",
    "    if len(ds_dives_nonan[k].ctd_data_point)>0:\n",
    "        temp = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_sorted[k].sigma0_QC, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0);\n",
    "    \n",
    "        dens_sorted_gridded = xr.concat([dens_sorted_gridded, temp], dim='dives')\n",
    "        \n",
    "        temp = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_sorted[k].CT_QC, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0);\n",
    "    \n",
    "        temp_sorted_gridded = xr.concat([temp_sorted_gridded, temp], dim='dives')\n",
    "        \n",
    "        temp = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_sorted[k].SA_QC, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0);\n",
    "    \n",
    "        salt_sorted_gridded = xr.concat([salt_sorted_gridded, temp], dim='dives')\n",
    "        \n",
    "        temp = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_sorted[k].oxygen_QC, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0);\n",
    "    \n",
    "        O2_sorted_gridded = xr.concat([O2_sorted_gridded, temp], dim='dives')\n",
    "        \n",
    "        temp = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_nonan[k].ctd_time, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0);\n",
    "    \n",
    "        time_sorted_gridded = xr.concat([time_sorted_gridded, temp], dim='dives')\n",
    "        \n",
    "        temp = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_nonan[k].latitude, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0);\n",
    "    \n",
    "        lat_sorted_gridded = xr.concat([lat_sorted_gridded, temp], dim='dives')\n",
    "        \n",
    "        temp = gt.grid_data(ds_dives_nonan[k].dives, ds_dives_nonan[k].ctd_pressure, ds_dives_nonan[k].longitude, \n",
    "                           bins = pres_bins, verbose=False, interp_lim=0);\n",
    "    \n",
    "        lon_sorted_gridded = xr.concat([lon_sorted_gridded, temp], dim='dives')\n",
    "        \n",
    "# Throw away the first column since it has been added twice. \n",
    "dens_sorted_gridded = dens_sorted_gridded[:,1:]\n",
    "temp_sorted_gridded = temp_sorted_gridded[:,1:]\n",
    "salt_sorted_gridded = salt_sorted_gridded[:,1:]\n",
    "O2_sorted_gridded   = O2_sorted_gridded[:,1:]\n",
    "time_sorted_gridded = time_sorted_gridded[:,1:]\n",
    "lat_sorted_gridded  = lat_sorted_gridded[:,1:]\n",
    "lon_sorted_gridded  = lon_sorted_gridded[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ad12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 13))\n",
    "\n",
    "plt.subplot(411)\n",
    "salt_gridded.plot()\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.subplot(412)\n",
    "temp_gridded.plot()\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.subplot(413)\n",
    "dens_gridded.plot()\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.subplot(414)\n",
    "O2_gridded.plot()\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d3b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 13))\n",
    "\n",
    "plt.subplot(411)\n",
    "salt_sorted_gridded.plot()\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.subplot(412)\n",
    "temp_sorted_gridded.plot()\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.subplot(413)\n",
    "dens_sorted_gridded.plot()\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.subplot(414)\n",
    "O2_sorted_gridded.plot()\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c442b029",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.subplot(311)\n",
    "(salt_sorted_gridded - salt_gridded).plot(vmin=-0.01)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.subplot(312)\n",
    "(temp_sorted_gridded - temp_gridded).plot(vmin=-0.1)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.subplot(313)\n",
    "(dens_sorted_gridded - dens_gridded).plot(vmin=-0.01)\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceb3571",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = bins=np.linspace(-0.02, 0.1, 200)\n",
    "dens_gridded.diff('ctd_pressure').plot.hist(bins=bins, label='Unsorted')\n",
    "dens_sorted_gridded.diff('ctd_pressure').plot.hist(bins=bins, label='Sorted', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15931e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 3.3))\n",
    "dens_gridded.diff('ctd_pressure').plot(vmin=-0.04)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8528cbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "ds_659_grid.Oxygen.plot(cmap=cmo.thermal)\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097d94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As expected sorting makes N2 purely positive. \n",
    "\n",
    "plt.figure(figsize=(14, 3.3))\n",
    "\n",
    "dens_sorted_gridded.diff('ctd_pressure').plot(vmax=0.06)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee3f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_659_grid = xr.merge([dens_sorted_gridded.rename('sigma0'), \n",
    "                        salt_sorted_gridded.rename('SA'), \n",
    "                        temp_sorted_gridded.rename('CT'),\n",
    "                        O2_sorted_gridded.rename('Oxygen'),\n",
    "                        time_sorted_gridded.rename('time'), \n",
    "                        lat_sorted_gridded.rename('latitude'), \n",
    "                        lon_sorted_gridded.rename('longitude')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sogos]",
   "language": "python",
   "name": "conda-env-sogos-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
